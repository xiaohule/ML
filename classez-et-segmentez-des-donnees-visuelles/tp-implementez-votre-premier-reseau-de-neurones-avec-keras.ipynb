{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/9d/c129d78e6b942303b762ccfdf1f8339de80c5e6021b14ef0c99ec5bdc6aa/numpy-1.16.3-cp37-cp37m-win_amd64.whl (11.9MB)\n",
      "Installing collected packages: numpy\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\n",
      "Successfully installed numpy-1.16.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install numpy --upgrade  ##Numpy upgrade to get inline with TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation de VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "# import numpy\n",
    "\n",
    "my_VGG16 = Sequential()  # Création d'un réseau de neurones vide \n",
    "\n",
    "# Ajout de la première couche de convolution, suivie d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(64, (3, 3), input_shape=(224, 224, 3), padding='same', activation='relu'))\n",
    "\n",
    "# Ajout de la deuxième couche de convolution, suivie  d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "\n",
    "# Ajout de la première couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#block 2\n",
    "my_VGG16.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#block 3\n",
    "my_VGG16.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#block 4\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "#block 5\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "\n",
    "my_VGG16.add(Flatten())  # Conversion des matrices 3D en vecteur 1D\n",
    "\n",
    "# Ajout de la première couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(4096, activation='relu'))\n",
    "\n",
    "# Ajout de la deuxième couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(4096, activation='relu'))\n",
    "\n",
    "# Ajout de la dernière couche fully-connected qui permet de classifier\n",
    "my_VGG16.add(Dense(1000, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_VGG16.compile('sgd','categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation du VGG-16 pré-entraîné de Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 557s 1us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16() # Création du modèle VGG-16 implementé par Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "img = load_img('cat2.jpg', target_size=(224, 224))  # Charger l'image\n",
    "img = img_to_array(img)  # Convertir en tableau numpy\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
    "img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(img)  # Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 : [('n01774750', 'tarantula', 0.9849915), ('n01773549', 'barn_spider', 0.008899479), ('n01775062', 'wolf_spider', 0.0027851427)]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "# Afficher les 3 classes les plus probables\n",
    "print('Top 3 :', decode_predictions(y, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.output\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 10 classes\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Stratégie #1 : fine-tuning total\n",
    "# for layer in model.layers:\n",
    "#    layer.trainable = True\n",
    "\n",
    "#Stratégie #2 : extraction de features\n",
    "for layer in model.layers:\n",
    "   layer.trainable = False\n",
    "\n",
    "# #Stratégie #3 : fine-tuning partiel\n",
    "# e.g. Ne pas entraîner les 5 premières couches (les plus basses) \n",
    "# for layer in model.layers[:5]:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-84939b1042b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Entraîner sur les données d'entraînement (X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "# Compiler le modèle \n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "model_info = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
